{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa1ce09-b44e-44e6-9df1-09cb97705d0b",
   "metadata": {},
   "source": [
    "## Dependency set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367f6914-7274-4fb0-a956-5cc275064cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.7.0 (default, Oct  9 2018, 10:31:47) \n",
      "[GCC 7.3.0]\n",
      "Spark version: 2.4.8\n"
     ]
    }
   ],
   "source": [
    "# set the environment path to find Recommenders\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, FloatType, IntegerType, LongType, StructType, StructField\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import HashingTF, CountVectorizer, VectorAssembler\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.utils.notebook_utils import is_jupyter\n",
    "from recommenders.datasets.spark_splitters import spark_random_split\n",
    "from recommenders.evaluation.spark_evaluation import SparkRatingEvaluation, SparkRankingEvaluation, SparkDiversityEvaluation\n",
    "from recommenders.utils.spark_utils import start_or_get_spark\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Spark version: {}\".format(pyspark.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a65c2e-1811-4daa-90a4-c25fb9656aa0",
   "metadata": {},
   "source": [
    "### Set the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "073ad615-1aaa-4247-9b67-ff5f2cd96c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'\n",
    "\n",
    "# user, item column names\n",
    "COL_USER=\"UserId\"\n",
    "COL_ITEM=\"MovieId\"\n",
    "COL_RATING=\"Rating\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ebcb0c-201b-4d20-af7c-7ddbec27d3a8",
   "metadata": {},
   "source": [
    "## 1. Set up Spark context\n",
    "The following settings work well for debugging locally on VM - change when running on a cluster. We set up a giant single executor with many threads and specify memory cap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5138073d-5f79-48b2-beb6-f78a153a1d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = start_or_get_spark(\"ALS PySpark\", memory=\"16g\")\n",
    "\n",
    "spark.conf.set(\"spark.sql.crossJoin.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc72a7b0-e30c-4731-8a4e-0f21bd3da6e0",
   "metadata": {},
   "source": [
    "## 2. Download the MovieLens dataset\n",
    "\n",
    "Note can set different size above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de395d00-8f96-4318-92fd-036557a91e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.81k/4.81k [00:00<00:00, 13.9kKB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+---------+--------------------+------+\n",
      "|MovieId|UserId|Rating|Timestamp|               title|genres|\n",
      "+-------+------+------+---------+--------------------+------+\n",
      "|     26|   138|   5.0|879024232|Brothers McMullen...|Comedy|\n",
      "|     26|   224|   3.0|888104153|Brothers McMullen...|Comedy|\n",
      "|     26|    18|   4.0|880129731|Brothers McMullen...|Comedy|\n",
      "|     26|   222|   3.0|878183043|Brothers McMullen...|Comedy|\n",
      "|     26|    43|   5.0|883954901|Brothers McMullen...|Comedy|\n",
      "|     26|   201|   4.0|884111927|Brothers McMullen...|Comedy|\n",
      "|     26|   299|   4.0|878192601|Brothers McMullen...|Comedy|\n",
      "|     26|    95|   3.0|880571951|Brothers McMullen...|Comedy|\n",
      "|     26|    89|   3.0|879459909|Brothers McMullen...|Comedy|\n",
      "|     26|   361|   3.0|879440941|Brothers McMullen...|Comedy|\n",
      "|     26|   194|   3.0|879522240|Brothers McMullen...|Comedy|\n",
      "|     26|   391|   5.0|877399745|Brothers McMullen...|Comedy|\n",
      "|     26|   345|   3.0|884993555|Brothers McMullen...|Comedy|\n",
      "|     26|   303|   4.0|879468307|Brothers McMullen...|Comedy|\n",
      "|     26|   401|   3.0|891033395|Brothers McMullen...|Comedy|\n",
      "|     26|   429|   3.0|882386333|Brothers McMullen...|Comedy|\n",
      "|     26|   293|   3.0|888907015|Brothers McMullen...|Comedy|\n",
      "|     26|   270|   5.0|876954995|Brothers McMullen...|Comedy|\n",
      "|     26|   442|   3.0|883388576|Brothers McMullen...|Comedy|\n",
      "|     26|   342|   2.0|875320037|Brothers McMullen...|Comedy|\n",
      "+-------+------+------+---------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note: The DataFrame-based API for ALS currently only supports integers for user and item ids.\n",
    "schema = StructType(\n",
    "    (\n",
    "        StructField(COL_USER, IntegerType()),\n",
    "        StructField(COL_ITEM, IntegerType()),\n",
    "        StructField(COL_RATING, FloatType()),\n",
    "        StructField(\"Timestamp\", LongType()),\n",
    "    )\n",
    ")\n",
    "\n",
    "data = movielens.load_spark_df(spark, size=MOVIELENS_DATA_SIZE, schema=schema, title_col=\"title\", genres_col=\"genres\")\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9523f4-e8e2-4590-a0e1-75b3260d1c79",
   "metadata": {},
   "source": [
    "### Split the data using the Spark random splitter provided in utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e7a60f5-ccd8-4565-82a0-40f6bf1fe9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N train_df 75066\n",
      "N test_df 24934\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = spark_random_split(data.select(COL_USER, COL_ITEM, COL_RATING), ratio=0.75, seed=123)\n",
    "print (\"N train_df\", train_df.cache().count())\n",
    "print (\"N test_df\", test_df.cache().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5643205-d96b-4dd3-9458-26eacb16a895",
   "metadata": {},
   "source": [
    "### Get all possible user-item pairs\n",
    "Note: We assume that training data contains all users and all catalog items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bf76596-5770-4ebd-b799-d57db558fc5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "users = train_df.select(COL_USER).distinct()\n",
    "items = train_df.select(COL_ITEM).distinct()\n",
    "user_item = users.crossJoin(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02eaf46d-661e-4b4f-ac2f-bf2d41585ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "1633\n",
      "1539919\n"
     ]
    }
   ],
   "source": [
    "print(users.count())\n",
    "print(items.count())\n",
    "print(user_item.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aea4c5-6ca9-4584-9a1b-d4d0925b1cfd",
   "metadata": {},
   "source": [
    "## 3. Train the ALS model on the training data, and get the top-k recommendations for our testing data\n",
    "\n",
    "To predict movie ratings, we use the rating data in the training set as users' explicit feedback. The hyperparameters used in building the model are referenced from here. We do not constrain the latent factors (nonnegative = False) in order to allow for both positive and negative preferences towards movies. Timing will vary depending on the machine being used to train.\n",
    "\n",
    "<b>Note</b> on SCC with gpu it takes 2 sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e241c00f-75b4-4898-af0a-c7833f59df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\n",
    "    \"userCol\": COL_USER,\n",
    "    \"itemCol\": COL_ITEM,\n",
    "    \"ratingCol\": COL_RATING,\n",
    "}\n",
    "\n",
    "\n",
    "##could modify and have another algo here\n",
    "als = ALS(\n",
    "    rank=10,\n",
    "    maxIter=15,\n",
    "    implicitPrefs=False,\n",
    "    regParam=0.05,\n",
    "    coldStartStrategy='drop',\n",
    "    nonnegative=False,\n",
    "    seed=42,\n",
    "    **header\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5899be8a-b0a1-43bf-848d-36ef71d9d617",
   "metadata": {},
   "source": [
    "Note here the model object is generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7b36ba8-8f79-49ae-9ae1-e5361fda77cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 2.8200885746628046 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model = als.fit(train_df)\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94f08e8-2564-4df9-b813-c87311f3cfc5",
   "metadata": {},
   "source": [
    "In the movie recommendation use case, recommending movies that have been rated by the users does not make sense. Therefore, the rated movies are removed from the recommended items.\n",
    "\n",
    "In order to achieve this, we recommend all movies to all users, and then remove the user-movie pairs that exist in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "003156b9-6316-4ae0-a984-70310dd218c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1464853\n",
      "9430\n"
     ]
    }
   ],
   "source": [
    "# Score all user-item pairs\n",
    "dfs_pred = model.transform(user_item)\n",
    "\n",
    "# Remove seen items.\n",
    "dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n",
    "    train_df.alias(\"train\"),\n",
    "    (dfs_pred[COL_USER] == train_df[COL_USER]) & (dfs_pred[COL_ITEM] == train_df[COL_ITEM]),\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "top_all = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[\"train.Rating\"].isNull()) \\\n",
    "    .select('pred.' + COL_USER, 'pred.' + COL_ITEM, 'pred.' + \"prediction\")\n",
    "\n",
    "print(top_all.count())\n",
    "    \n",
    "window = Window.partitionBy(COL_USER).orderBy(F.col(\"prediction\").desc())    \n",
    "top_k_reco = top_all.select(\"*\", F.row_number().over(window).alias(\"rank\")).filter(F.col(\"rank\") <= TOP_K).drop(\"rank\")\n",
    " \n",
    "print(top_k_reco.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23954fd1-1662-41cb-8f30-1485eb0c7057",
   "metadata": {},
   "source": [
    "## 4. Random Recommender - For comparison\n",
    "We define a recommender which randomly recommends unseen items to each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af3a57c0-44ff-4ff2-a88a-65de4956403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random recommender\n",
    "window = Window.partitionBy(COL_USER).orderBy(F.rand()) # note understand better\n",
    "\n",
    "# randomly generated recommendations for each user\n",
    "pred_df = (\n",
    "  train_df\n",
    "  # join training data with all possible user-item pairs (seen in training)\n",
    "  .join(user_item,\n",
    "        on=[COL_USER, COL_ITEM],\n",
    "        how=\"right\"\n",
    "  )\n",
    "  # get user-item pairs that were not seen in the training data\n",
    "  .filter(F.col(COL_RATING).isNull())\n",
    "  # count items for each user (randomly sorting them)\n",
    "  .withColumn(\"score\", F.row_number().over(window))\n",
    "  # get the top k items per user\n",
    "  .filter(F.col(\"score\") <= TOP_K)\n",
    "  .drop(COL_RATING)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42ea9ee-68a6-45f3-a69b-e6a540628fe7",
   "metadata": {},
   "source": [
    "## 5. ALS vs Random Recommenders Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442e1ec7-a28e-4976-86a3-ed4fe7bb18c6",
   "metadata": {},
   "source": [
    "### Metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31492a2e-7803-44c4-9f07-6040e1dd769c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##different diversity metrics parsed form recall eval....object?\n",
    "def get_ranking_results(ranking_eval):\n",
    "    metrics = {\n",
    "        \"Precision@k\": ranking_eval.precision_at_k(),\n",
    "        \"Recall@k\": ranking_eval.recall_at_k(),\n",
    "        \"NDCG@k\": ranking_eval.ndcg_at_k(),\n",
    "        \"Mean average precision\": ranking_eval.map_at_k()\n",
    "      \n",
    "    }\n",
    "    return metrics  \n",
    "\n",
    "##different diversity metrics parsed form diversity eval....object?\n",
    "def get_diversity_results(diversity_eval):\n",
    "    metrics = {\n",
    "        \"catalog_coverage\":diversity_eval.catalog_coverage(),\n",
    "        \"distributional_coverage\":diversity_eval.distributional_coverage(), \n",
    "        \"novelty\": diversity_eval.novelty(), \n",
    "        \"diversity\": diversity_eval.diversity(), \n",
    "        \"serendipity\": diversity_eval.serendipity()\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff705dd3-c53f-4c5c-ad84-9d427020b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(data, algo, k, ranking_metrics, diversity_metrics):\n",
    "    summary = {\"Data\": data, \"Algo\": algo, \"K\": k}\n",
    "\n",
    "    if ranking_metrics is None:\n",
    "        ranking_metrics = {           \n",
    "            \"Precision@k\": np.nan,\n",
    "            \"Recall@k\": np.nan,            \n",
    "            \"nDCG@k\": np.nan,\n",
    "            \"MAP\": np.nan,\n",
    "        }\n",
    "    summary.update(ranking_metrics)\n",
    "    summary.update(diversity_metrics)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd06f9-1e58-491f-b9db-eb447b47b308",
   "metadata": {},
   "source": [
    "### ALS Recommender Performance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "009ba15a-52d5-4741-8e6a-f1a020be92d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_ranking_eval = SparkRankingEvaluation(\n",
    "    test_df, \n",
    "    top_all, \n",
    "    k = TOP_K, \n",
    "    col_user=\"UserId\", \n",
    "    col_item=\"MovieId\",\n",
    "    col_rating=\"Rating\", \n",
    "    col_prediction=\"prediction\",\n",
    "    relevancy_method=\"top_k\"\n",
    ")\n",
    "\n",
    "als_ranking_metrics = get_ranking_results(als_ranking_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "250bdd42-059c-4af6-b9e9-e787f5edcb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_diversity_eval = SparkDiversityEvaluation(\n",
    "    train_df = train_df, \n",
    "    reco_df = top_k_reco,\n",
    "    col_user = COL_USER, \n",
    "    col_item = COL_ITEM\n",
    ")\n",
    "\n",
    "als_diversity_metrics = get_diversity_results(als_diversity_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "987be592-8f55-4432-8867-5f26cf0b1fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Data': '100k', 'Algo': 'als', 'K': 10, 'Precision@k': 0.04729586426299045, 'Recall@k': 0.01601477257161039, 'NDCG@k': 0.04309703774263865, 'Mean average precision': 0.004579045144199097, 'catalog_coverage': 0.385793018983466, 'distributional_coverage': 7.967257304554895, 'novelty': 11.659775792745016, 'diversity': 0.8922765632097469, 'serendipity': 0.8787329333952111}\n"
     ]
    }
   ],
   "source": [
    "als_results = generate_summary(MOVIELENS_DATA_SIZE, \"als\", TOP_K, als_ranking_metrics, als_diversity_metrics)\n",
    "print(als_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a1dd24-d7de-4f69-aa84-538a359c4db8",
   "metadata": {},
   "source": [
    "## Random Recommender Performance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "411976b1-01d6-4422-a05e-9edb51cb8738",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ranking_eval = SparkRankingEvaluation(\n",
    "    test_df,\n",
    "    pred_df,\n",
    "    col_user=COL_USER,\n",
    "    col_item=COL_ITEM,\n",
    "    col_rating=COL_RATING,\n",
    "    col_prediction=\"score\",\n",
    "    k=TOP_K,\n",
    ")\n",
    "\n",
    "random_ranking_metrics = get_ranking_results(random_ranking_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e06a5918-8e5b-401e-a7b1-6d774f03202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_diversity_eval = SparkDiversityEvaluation(\n",
    "    train_df = train_df, \n",
    "    reco_df = pred_df, \n",
    "    col_user = COL_USER, \n",
    "    col_item = COL_ITEM\n",
    ")\n",
    "  \n",
    "random_diversity_metrics = get_diversity_results(random_diversity_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1945440-78f7-4f73-8d3b-2ca00a82e2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Data': '100k', 'Algo': 'random', 'K': 10, 'Precision@k': 0.015588547189819722, 'Recall@k': 0.005122908752536401, 'NDCG@k': 0.015613718941249626, 'Mean average precision': 0.0015506651228243207, 'catalog_coverage': 0.9957134109001837, 'distributional_coverage': 10.537609381993875, 'novelty': 12.151949574353871, 'diversity': 0.9235406134614499, 'serendipity': 0.8933719844556243}\n"
     ]
    }
   ],
   "source": [
    "random_results = generate_summary(MOVIELENS_DATA_SIZE, \"random\", TOP_K, random_ranking_metrics, random_diversity_metrics)\n",
    "print(random_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7a63fe-95e3-4f40-b5ce-fc3c9b8403d7",
   "metadata": {},
   "source": [
    "## Result Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1840a7b5-d460-4f0a-ae44-d1b62b29f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Data\", \"Algo\", \"K\", \"Precision@k\", \"Recall@k\", \"NDCG@k\", \"Mean average precision\",\"catalog_coverage\", \"distributional_coverage\",\"novelty\", \"diversity\", \"serendipity\" ]\n",
    "df_results = pd.DataFrame(columns=cols)\n",
    "\n",
    "df_results.loc[1] = als_results \n",
    "df_results.loc[2] = random_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4087b6c-1e4a-4be8-a06d-35bd257233ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Algo</th>\n",
       "      <th>K</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Mean average precision</th>\n",
       "      <th>catalog_coverage</th>\n",
       "      <th>distributional_coverage</th>\n",
       "      <th>novelty</th>\n",
       "      <th>diversity</th>\n",
       "      <th>serendipity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100k</td>\n",
       "      <td>als</td>\n",
       "      <td>10</td>\n",
       "      <td>0.047296</td>\n",
       "      <td>0.016015</td>\n",
       "      <td>0.043097</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.385793</td>\n",
       "      <td>7.967257</td>\n",
       "      <td>11.659776</td>\n",
       "      <td>0.892277</td>\n",
       "      <td>0.878733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100k</td>\n",
       "      <td>random</td>\n",
       "      <td>10</td>\n",
       "      <td>0.015589</td>\n",
       "      <td>0.005123</td>\n",
       "      <td>0.015614</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.995713</td>\n",
       "      <td>10.537609</td>\n",
       "      <td>12.151950</td>\n",
       "      <td>0.923541</td>\n",
       "      <td>0.893372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data    Algo   K  Precision@k  Recall@k    NDCG@k  Mean average precision  \\\n",
       "1  100k     als  10     0.047296  0.016015  0.043097                0.004579   \n",
       "2  100k  random  10     0.015589  0.005123  0.015614                0.001551   \n",
       "\n",
       "   catalog_coverage  distributional_coverage    novelty  diversity  \\\n",
       "1          0.385793                 7.967257  11.659776   0.892277   \n",
       "2          0.995713                10.537609  12.151950   0.923541   \n",
       "\n",
       "   serendipity  \n",
       "1     0.878733  \n",
       "2     0.893372  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78891325-9f49-4e5b-ae6f-c13c08162cc5",
   "metadata": {},
   "source": [
    "## 6. Calculate diversity metrics using item feature vector based item-item similarity\n",
    "\n",
    "In the above section we calculate diversity metrics using item co-occurrence count based item-item similarity. In the scenarios when item features are available, we may want to calculate item-item similarity based on item feature vectors. In this section, we show how to calculate diversity metrics using item feature vector based item-item similarity.\n",
    "\n",
    "That is content based- look at item-item feature similiarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "654640d5-ada9-49a1-88a3-ddbbeb306dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get movie features \"title\" and \"genres\"\n",
    "movies = (\n",
    "    data.groupBy(\"MovieId\", \"title\", \"genres\").count()\n",
    "    .na.drop()  # remove rows with null values\n",
    "    .withColumn(\"genres\", F.split(F.col(\"genres\"), \"\\|\"))  # convert to array of genres\n",
    "    .withColumn(\"title\", F.regexp_replace(F.col(\"title\"), \"[\\(),:^0-9]\", \"\"))  # remove year from title\n",
    "    .drop(\"count\")  # remove unused columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4efc47a0-43d7-4db5-a904-bc5336767192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize \"title\" column\n",
    "title_tokenizer = Tokenizer(inputCol=\"title\", outputCol=\"title_words\")\n",
    "tokenized_data = title_tokenizer.transform(movies)\n",
    "\n",
    "# remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"title_words\", outputCol=\"text\")\n",
    "clean_data = remover.transform(tokenized_data).drop(\"title\", \"title_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07527c1f-0bd2-40fd-a1c2-6c2d500fa260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------------------------------+\n",
      "|MovieId|features                                     |\n",
      "+-------+---------------------------------------------+\n",
      "|167    |(1043,[128,544,1025],[1.0,1.0,1.0])          |\n",
      "|1343   |(1043,[38,300,1024],[1.0,1.0,1.0])           |\n",
      "|1607   |(1043,[592,821,1024],[1.0,1.0,1.0])          |\n",
      "|966    |(1043,[389,502,1028],[1.0,1.0,1.0])          |\n",
      "|9      |(1043,[11,342,1014,1024],[1.0,1.0,1.0,1.0])  |\n",
      "|1230   |(1043,[597,740,902,1025],[1.0,1.0,1.0,1.0])  |\n",
      "|1118   |(1043,[702,1025],[1.0,1.0])                  |\n",
      "|673    |(1043,[169,690,1027,1040],[1.0,1.0,1.0,1.0]) |\n",
      "|879    |(1043,[909,1026,1027,1034],[1.0,1.0,1.0,1.0])|\n",
      "|66     |(1043,[256,1025,1028],[1.0,1.0,1.0])         |\n",
      "+-------+---------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert text input into feature vectors\n",
    "\n",
    "# step 1: perform HashingTF on column \"text\"\n",
    "text_hasher = HashingTF(inputCol=\"text\", outputCol=\"text_features\", numFeatures=1024)\n",
    "hashed_data = text_hasher.transform(clean_data)\n",
    "\n",
    "# step 2: fit a CountVectorizerModel from column \"genres\".\n",
    "count_vectorizer = CountVectorizer(inputCol=\"genres\", outputCol=\"genres_features\")\n",
    "count_vectorizer_model = count_vectorizer.fit(hashed_data)\n",
    "vectorized_data = count_vectorizer_model.transform(hashed_data)\n",
    "\n",
    "# step 3: assemble features into a single vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"text_features\", \"genres_features\"],\n",
    "    outputCol=\"features\",\n",
    ")\n",
    "feature_data = assembler.transform(vectorized_data).select(\"MovieId\", \"features\")\n",
    "\n",
    "feature_data.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d573f030-12f6-4733-98a0-ad6c469ff6a6",
   "metadata": {},
   "source": [
    "The features column is represented with a SparseVector object. For example, in the feature vector (1043,[128,544,1025],[1.0,1.0,1.0]), 1043 is the vector length, indicating the vector consisting of 1043 item features. The values at index positions 128,544,1025 are 1.0, and the values at other positions are all 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dd8a0b8-1fb5-48e8-b372-56c83bfce21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8738984131037538\n",
      "0.8873467159479473\n"
     ]
    }
   ],
   "source": [
    "als_eval = SparkDiversityEvaluation(\n",
    "    train_df = train_df, \n",
    "    reco_df = top_k_reco,\n",
    "    item_feature_df = feature_data, \n",
    "    item_sim_measure=\"item_feature_vector\",\n",
    "    col_user = COL_USER, \n",
    "    col_item = COL_ITEM\n",
    ")\n",
    "\n",
    "als_diversity=als_eval.diversity()\n",
    "als_serendipity=als_eval.serendipity()\n",
    "print(als_diversity)\n",
    "print(als_serendipity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd28408d-b0ee-4472-8bc3-824f2ddea612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8986456855062992\n",
      "0.8944051547993165\n"
     ]
    }
   ],
   "source": [
    "random_eval = SparkDiversityEvaluation(\n",
    "    train_df = train_df, \n",
    "    reco_df = pred_df, \n",
    "    item_feature_df = feature_data, \n",
    "    item_sim_measure=\"item_feature_vector\",    \n",
    "    col_user = COL_USER, \n",
    "    col_item = COL_ITEM\n",
    ")\n",
    "  \n",
    "random_diversity=random_eval.diversity()\n",
    "random_serendipity=random_eval.serendipity()\n",
    "print(random_diversity)\n",
    "print(random_serendipity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c85801ca-fb70-461c-a877-4c722a23f24f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cleanup spark instance\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2c3d66-bfc0-4b2a-8480-0c00011aef03",
   "metadata": {},
   "source": [
    "## References\n",
    "The metric definitions / formulations are based on the following references:\n",
    "\n",
    "P. Castells, S. Vargas, and J. Wang, Novelty and diversity metrics for recommender systems: choice, discovery and relevance, ECIR 2011\n",
    "G. Shani and A. Gunawardana, Evaluating recommendation systems, Recommender Systems Handbook pp. 257-297, 2010.\n",
    "E. Yan, Serendipity: Accuracy’s unpopular best friend in recommender Systems, eugeneyan.com, April 2020\n",
    "Y.C. Zhang, D.Ó. Séaghdha, D. Quercia and T. Jambor, Auralist: introducing serendipity into music recommendation, WSDM 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1363d-6d3f-4a38-b733-f9b49edcae02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condarec",
   "language": "python",
   "name": "condarec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
