{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "440e73c0-4876-4e8e-8363-b4ecd7c251c5",
   "metadata": {},
   "source": [
    "# ALS\n",
    "https://github.com/microsoft/recommenders/blob/main/examples/03_evaluate/als_movielens_diversity_metrics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e8794fa-1cf8-44e4-b709-65b7adfc8336",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.7.0 (default, Oct  9 2018, 10:31:47) \n",
      "[GCC 7.3.0]\n",
      "Spark version: 2.4.8\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, FloatType, IntegerType, LongType, StructType, StructField\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import HashingTF, CountVectorizer, VectorAssembler\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.utils.notebook_utils import is_jupyter\n",
    "from recommenders.datasets.spark_splitters import spark_random_split\n",
    "from recommenders.evaluation.spark_evaluation import SparkRatingEvaluation, SparkRankingEvaluation, SparkDiversityEvaluation\n",
    "from recommenders.utils.spark_utils import start_or_get_spark\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Spark version: {}\".format(pyspark.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcddc28-7ab5-4f16-bcab-0d8418cdf68d",
   "metadata": {},
   "source": [
    "## Set Paramters for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77ca9d12-05c8-4f7d-b494-616ab33e10d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 10\n",
    "\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '1m'\n",
    "\n",
    "# user, item column names\n",
    "COL_USER=\"UserId\"\n",
    "COL_ITEM=\"MovieId\"\n",
    "COL_RATING=\"Rating\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1308245f-4891-4ec7-b602-cda689983323",
   "metadata": {},
   "source": [
    "## Spark environment and Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3931f6a3-0fd8-42cf-9b5a-cc34ff53868d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://scc-ge4.scc.bu.edu:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.8</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ALS PySpark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2aeade8bc4e0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = start_or_get_spark(\"ALS PySpark\", memory=\"16g\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a179fd5-42f4-4c3b-95b0-1e57bbf08fe4",
   "metadata": {},
   "source": [
    "Setting cross-join to enabled, because pyspark has ways to disable it otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30ba9906-6d35-4b3c-8f24-2a0b1b30e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.crossJoin.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441fb9a6-2d43-4be5-93b9-055a11d7263b",
   "metadata": {},
   "source": [
    "Creating column types/names with struct and then loading the built in movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "250051b8-a30d-4fbb-bb31-e43f2e3a583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The DataFrame-based API for ALS currently only supports integers for user and item ids.\n",
    "schema = StructType(\n",
    "    (\n",
    "        StructField(COL_USER, IntegerType()),\n",
    "        StructField(COL_ITEM, IntegerType()),\n",
    "        StructField(COL_RATING, FloatType()),\n",
    "        StructField(\"Timestamp\", LongType()),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff74cae0-b9f7-4768-809f-957302e0864b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.78k/5.78k [00:03<00:00, 1.91kKB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(MovieId,IntegerType,true),StructField(UserId,IntegerType,true),StructField(Rating,FloatType,true),StructField(Timestamp,LongType,true),StructField(title,StringType,true),StructField(genres,StringType,true)))\n",
      "+-------+------+------+----------+--------------+------+\n",
      "|MovieId|UserId|Rating| Timestamp|         title|genres|\n",
      "+-------+------+------+----------+--------------+------+\n",
      "|     26|    18|   4.0| 978157335|Othello (1995)| Drama|\n",
      "|     26|    69|   4.0| 977882050|Othello (1995)| Drama|\n",
      "|     26|   229|   4.0|1039503573|Othello (1995)| Drama|\n",
      "|     26|   342|   4.0| 976338677|Othello (1995)| Drama|\n",
      "|     26|   524|   3.0| 976169012|Othello (1995)| Drama|\n",
      "|     26|   655|   3.0| 975699243|Othello (1995)| Drama|\n",
      "|     26|   748|   5.0| 975463153|Othello (1995)| Drama|\n",
      "|     26|   881|   3.0|1013536125|Othello (1995)| Drama|\n",
      "|     26|   890|   3.0| 976504835|Othello (1995)| Drama|\n",
      "|     26|   918|   4.0| 978241611|Othello (1995)| Drama|\n",
      "|     26|   963|   4.0| 980010331|Othello (1995)| Drama|\n",
      "|     26|   973|   4.0| 975861707|Othello (1995)| Drama|\n",
      "|     26|  1015|   3.0| 979452077|Othello (1995)| Drama|\n",
      "|     26|  1069|   3.0| 974944000|Othello (1995)| Drama|\n",
      "|     26|  1120|   3.0| 975437016|Othello (1995)| Drama|\n",
      "|     26|  1150|   3.0| 974873825|Othello (1995)| Drama|\n",
      "|     26|  1182|   2.0| 974853616|Othello (1995)| Drama|\n",
      "|     26|  1203|   4.0| 975174874|Othello (1995)| Drama|\n",
      "|     26|  1279|   3.0| 974853109|Othello (1995)| Drama|\n",
      "|     26|  1314|   1.0| 975532625|Othello (1995)| Drama|\n",
      "+-------+------+------+----------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = movielens.load_spark_df(spark, size=MOVIELENS_DATA_SIZE, schema=schema, title_col=\"title\", genres_col=\"genres\")\n",
    "print(data.schema)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632cc2fe-bea7-4ef6-9cb6-d81eb9e5a6aa",
   "metadata": {},
   "source": [
    "split data, ratio argument indicates the ratio of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0ba26f0-b9ea-492e-96b3-56360fff197f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N train_df 750336\n",
      "+------+-------+------+\n",
      "|UserId|MovieId|Rating|\n",
      "+------+-------+------+\n",
      "|     5|     29|   5.0|\n",
      "|    10|   2453|   4.0|\n",
      "|    10|   2529|   4.0|\n",
      "|    17|   2529|   4.0|\n",
      "|    18|     26|   4.0|\n",
      "|    19|   2529|   3.0|\n",
      "|    23|     29|   3.0|\n",
      "|    23|   2529|   3.0|\n",
      "|    26|   3506|   4.0|\n",
      "|    29|    474|   2.0|\n",
      "|    29|   2529|   5.0|\n",
      "|    33|    474|   5.0|\n",
      "|    33|   2529|   5.0|\n",
      "|    35|   3091|   5.0|\n",
      "|    36|    474|   5.0|\n",
      "|    36|   2250|   4.0|\n",
      "|    36|   2529|   5.0|\n",
      "|    42|   2529|   5.0|\n",
      "|    45|   1677|   2.0|\n",
      "|    48|    474|   3.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "N test_df 249873\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = spark_random_split(data.select(COL_USER, COL_ITEM, COL_RATING), ratio=0.75, seed=123)\n",
    "print (\"N train_df\", train_df.cache().count())\n",
    "train_df.show()\n",
    "print (\"N test_df\", test_df.cache().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8a5580d-31f8-4c3d-99cd-81442e967f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000209\n"
     ]
    }
   ],
   "source": [
    "print(data.cache().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453d787d-11ce-4b6c-beff-6b18f8ea73c2",
   "metadata": {},
   "source": [
    "Check average number of ratings per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f283906a-c96d-40d4-8b2b-8ccf696a069f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|UserId|count|\n",
      "+------+-----+\n",
      "|  4169| 2314|\n",
      "|  1680| 1850|\n",
      "|  4277| 1743|\n",
      "|  1941| 1595|\n",
      "|  1181| 1521|\n",
      "|   889| 1518|\n",
      "|  3618| 1344|\n",
      "|  2063| 1323|\n",
      "|  1150| 1302|\n",
      "|  1015| 1286|\n",
      "|  5795| 1277|\n",
      "|  4344| 1271|\n",
      "|  1980| 1260|\n",
      "|  2909| 1258|\n",
      "|  1449| 1243|\n",
      "|  4510| 1240|\n",
      "|   424| 1226|\n",
      "|  4227| 1222|\n",
      "|  5831| 1220|\n",
      "|  3841| 1216|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "6040\n",
      "+-----------------+\n",
      "|       avg(count)|\n",
      "+-----------------+\n",
      "|165.5975165562914|\n",
      "+-----------------+\n",
      "\n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|        20|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rowsPerUser = data.groupBy(\"UserId\").count().sort('count', ascending = False)\n",
    "rowsPerUser.show()\n",
    "print(rowsPerUser.cache().count())\n",
    "rowsPerUser.agg({'count': 'mean'}).show()\n",
    "rowsPerUser.agg({'count': 'min'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da83d3a4-dad4-4911-ad39-ac38c582a27a",
   "metadata": {},
   "source": [
    "## Use cross join to create all possible user-item pairs\n",
    "Use training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7fd92c51-b67d-44d5-8eb1-49478164e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = train_df.select(COL_USER).distinct()\n",
    "items = train_df.select(COL_ITEM).distinct()\n",
    "user_item = users.crossJoin(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d976837f-4276-4c3d-a959-87cb4e9b5f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040\n",
      "3670\n",
      "22166800\n",
      "+------+-------+\n",
      "|UserId|MovieId|\n",
      "+------+-------+\n",
      "|   148|    463|\n",
      "|   148|   1591|\n",
      "|   148|   3918|\n",
      "|   148|   3175|\n",
      "|   148|    496|\n",
      "|   148|   1238|\n",
      "|   148|   3794|\n",
      "|   148|   1342|\n",
      "|   148|    833|\n",
      "|   148|   2366|\n",
      "|   148|   1829|\n",
      "|   148|    471|\n",
      "|   148|   1959|\n",
      "|   148|   1580|\n",
      "|   148|   2142|\n",
      "|   148|   2659|\n",
      "|   148|   2866|\n",
      "|   148|   1088|\n",
      "|   148|   2122|\n",
      "|   148|   1645|\n",
      "+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(users.count())\n",
    "print(items.count())\n",
    "print(user_item.count())\n",
    "user_item.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ee0e6-66df-45c3-abc0-a8ed27dd4a3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train Model and get top K recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dede480-5dce-422d-a5e2-1cb9aacb0eef",
   "metadata": {},
   "source": [
    "als model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28af6d85-e362-4753-b297-f6ea22452aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\n",
    "    \"userCol\": COL_USER,\n",
    "    \"itemCol\": COL_ITEM,\n",
    "    \"ratingCol\": COL_RATING,\n",
    "}\n",
    "\n",
    "\n",
    "##could modify and have another algo here\n",
    "als = ALS(\n",
    "    rank=10,\n",
    "    maxIter=15,\n",
    "    implicitPrefs=False,\n",
    "    regParam=0.05,\n",
    "    coldStartStrategy='drop',\n",
    "    nonnegative=False,\n",
    "    seed=42,\n",
    "    **header\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b908d6-cbff-42dc-bce4-c7c93f6906b9",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee0764be-5490-45f7-9661-e48733fa5e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 2.611721148714423 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model = als.fit(train_df)\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18be8a61-1b8d-43e1-9ca5-f3abaeb0895e",
   "metadata": {},
   "source": [
    "recommend all movies to all users and then takeout the ones already in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6ed2c28-09a0-416c-a13b-47e02b9b7697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "|UserId|MovieId|prediction|\n",
      "+------+-------+----------+\n",
      "|   148|    148| 1.9932647|\n",
      "|   463|    148| 2.1618307|\n",
      "|   471|    148| 3.3621922|\n",
      "|   496|    148| 2.3596911|\n",
      "|   833|    148| 3.3021572|\n",
      "|  1088|    148| 2.5344753|\n",
      "|  1238|    148|  2.794884|\n",
      "|  1342|    148| 1.7258394|\n",
      "|  1580|    148| 2.9216523|\n",
      "|  1591|    148|  3.609573|\n",
      "|  1645|    148| 2.4713356|\n",
      "|  1829|    148| 1.9832127|\n",
      "|  1959|    148| 3.5405562|\n",
      "|  2122|    148| 2.5934963|\n",
      "|  2142|    148| 1.4509761|\n",
      "|  2366|    148| 1.3390584|\n",
      "|  2659|    148| 3.3351188|\n",
      "|  2866|    148| 2.2846713|\n",
      "|  3175|    148|  3.468598|\n",
      "|  3749|    148| 2.9621146|\n",
      "+------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Score all user-item pairs\n",
    "dfs_pred = model.transform(user_item)\n",
    "dfs_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28e33e94-2407-4630-ac36-570409b62a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21416464\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1375.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 69 in stage 2354.0 failed 1 times, most recent failure: Lost task 69.0 in stage 2354.0 (TID 77041, localhost, executor driver): java.io.IOException: No space left on device\n\tat java.io.FileOutputStream.writeBytes(Native Method)\n\tat java.io.FileOutputStream.write(FileOutputStream.java:326)\n\tat org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:220)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:173)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)\n\tat java.io.DataOutputStream.write(DataOutputStream.java:107)\n\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.writeToStream(UnsafeRow.java:562)\n\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$1.writeValue(UnsafeRowSerializer.scala:69)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:370)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3388)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3369)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3368)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.GeneratedMethodAccessor353.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.IOException: No space left on device\n\tat java.io.FileOutputStream.writeBytes(Native Method)\n\tat java.io.FileOutputStream.write(FileOutputStream.java:326)\n\tat org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:220)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:173)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)\n\tat java.io.DataOutputStream.write(DataOutputStream.java:107)\n\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.writeToStream(UnsafeRow.java:562)\n\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$1.writeValue(UnsafeRowSerializer.scala:69)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-91bece60d5fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtop_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/condarec/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \"\"\"\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/condarec/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/condarec/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/condarec/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1375.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 69 in stage 2354.0 failed 1 times, most recent failure: Lost task 69.0 in stage 2354.0 (TID 77041, localhost, executor driver): java.io.IOException: No space left on device\n\tat java.io.FileOutputStream.writeBytes(Native Method)\n\tat java.io.FileOutputStream.write(FileOutputStream.java:326)\n\tat org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:220)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:173)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)\n\tat java.io.DataOutputStream.write(DataOutputStream.java:107)\n\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.writeToStream(UnsafeRow.java:562)\n\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$1.writeValue(UnsafeRowSerializer.scala:69)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:370)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3388)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3369)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3368)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.GeneratedMethodAccessor353.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.IOException: No space left on device\n\tat java.io.FileOutputStream.writeBytes(Native Method)\n\tat java.io.FileOutputStream.write(FileOutputStream.java:326)\n\tat org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:220)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:173)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)\n\tat java.io.DataOutputStream.write(DataOutputStream.java:107)\n\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.writeToStream(UnsafeRow.java:562)\n\tat org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$1.writeValue(UnsafeRowSerializer.scala:69)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "# Remove seen items - Remember we only used training data to create user_item\n",
    "dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n",
    "    train_df.alias(\"train\"),\n",
    "    (dfs_pred[COL_USER] == train_df[COL_USER]) & (dfs_pred[COL_ITEM] == train_df[COL_ITEM]),\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "top_all = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[\"train.Rating\"].isNull()) \\\n",
    "    .select('pred.' + COL_USER, 'pred.' + COL_ITEM, 'pred.' + \"prediction\")\n",
    "\n",
    "print(top_all.count())\n",
    "\n",
    "top_all.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6a06ea5-51ca-43d8-b581-b9426415a169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18860\n",
      "+------+-------+----------+\n",
      "|UserId|MovieId|prediction|\n",
      "+------+-------+----------+\n",
      "|   148|    919| 6.3261137|\n",
      "|   148|    353| 6.2676616|\n",
      "|   148|    968| 6.1783676|\n",
      "|   148|    253| 6.1438556|\n",
      "|   148|   1512| 5.9449964|\n",
      "|   148|   1227| 5.8750854|\n",
      "|   148|   1251| 5.6491814|\n",
      "|   148|    115|   5.64693|\n",
      "|   148|    244|  5.636389|\n",
      "|   148|     57| 5.4875755|\n",
      "|   148|     89|  5.465199|\n",
      "|   148|   1085| 5.4451227|\n",
      "|   148|   1001|  5.392377|\n",
      "|   148|    703| 5.3899245|\n",
      "|   148|    805| 5.3898864|\n",
      "|   148|   1449|  5.308111|\n",
      "|   148|   1104| 5.3005443|\n",
      "|   148|    626|  5.295541|\n",
      "|   148|   1240|  5.290914|\n",
      "|   148|   1478| 5.2802405|\n",
      "+------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy(COL_USER).orderBy(F.col(\"prediction\").desc())\n",
    "top_k_reco = top_all.select(\"*\", F.row_number().over(window).alias(\"rank\")).filter(F.col(\"rank\") <= TOP_K).drop(\"rank\")\n",
    " \n",
    "print(top_k_reco.count())\n",
    "top_k_reco.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a94ac5-8939-472b-9389-4f75285f42b3",
   "metadata": {},
   "source": [
    "## Metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4933988d-ae0b-4d5e-b947-2774d828c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "##different diversity metrics parsed form recall eval....object?\n",
    "def get_ranking_results(ranking_eval):\n",
    "    metrics = {\n",
    "        \"Precision@k\": ranking_eval.precision_at_k(),\n",
    "        \"Recall@k\": ranking_eval.recall_at_k(),\n",
    "        \"NDCG@k\": ranking_eval.ndcg_at_k(),\n",
    "        \"Mean average precision\": ranking_eval.map_at_k()\n",
    "      \n",
    "    }\n",
    "    return metrics  \n",
    "\n",
    "##different diversity metrics parsed form diversity eval....object?\n",
    "def get_diversity_results(diversity_eval):\n",
    "    metrics = {\n",
    "        \"catalog_coverage\":diversity_eval.catalog_coverage(),\n",
    "        \"distributional_coverage\":diversity_eval.distributional_coverage(), \n",
    "        \"novelty\": diversity_eval.novelty(), \n",
    "        \"diversity\": diversity_eval.diversity(), \n",
    "        \"serendipity\": diversity_eval.serendipity()\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def get_rating_results(rating_eval):\n",
    "    metrics = {\n",
    "     'rmse': rating_eval.rmse(),\n",
    "     'mean absolute error' : rating_eval.mae(),\n",
    "     'R squared': rating_eval.rsquared(),\n",
    "     'explained variance': rating_eval.exp_var()\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def generate_summary(data, algo, k, ranking_metrics, diversity_metrics):\n",
    "    summary = {\"Data\": data, \"Algo\": algo, \"K\": k}\n",
    "\n",
    "    if ranking_metrics is None:\n",
    "        ranking_metrics = {           \n",
    "            \"Precision@k\": np.nan,\n",
    "            \"Recall@k\": np.nan,            \n",
    "            \"nDCG@k\": np.nan,\n",
    "            \"MAP\": np.nan,\n",
    "        }\n",
    "        #update just adds to the back of the dictionary.\n",
    "    summary.update(ranking_metrics)\n",
    "    summary.update(diversity_metrics)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad773647-11a4-485c-bf7f-0cdcdb40824c",
   "metadata": {},
   "source": [
    "## ALS Ranking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b90ee0b-135d-4352-bca5-10a33ac9c8a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "als_ranking_eval = SparkRankingEvaluation(\n",
    "    test_df, \n",
    "    top_all, \n",
    "    k = TOP_K, \n",
    "    col_user=\"UserId\", \n",
    "    col_item=\"MovieId\",\n",
    "    col_rating=\"Rating\", \n",
    "    col_prediction=\"prediction\",\n",
    "    relevancy_method=\"top_k\"\n",
    ")\n",
    "\n",
    "als_ranking_metrics = get_ranking_results(als_ranking_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c08ad65-5d2c-48e4-ad8b-c5f6c3aecfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Mean average precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053287</td>\n",
       "      <td>0.038843</td>\n",
       "      <td>0.052833</td>\n",
       "      <td>0.007391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision@k  Recall@k    NDCG@k  Mean average precision\n",
       "1     0.053287  0.038843  0.052833                0.007391"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [ \"Precision@k\", \"Recall@k\", \"NDCG@k\", \"Mean average precision\"]\n",
    "ranking_results = pd.DataFrame(columns=cols)\n",
    "\n",
    "ranking_results.loc[1] = als_ranking_metrics\n",
    "\n",
    "ranking_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d377d-9ee9-4ef5-9267-2d4415b7feb8",
   "metadata": {},
   "source": [
    "## Diversity results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "523cbf54-fb5b-4242-b524-2832bac6ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_diversity_eval = SparkDiversityEvaluation(\n",
    "    train_df = train_df, \n",
    "    reco_df = top_k_reco,\n",
    "    col_user = COL_USER, \n",
    "    col_item = COL_ITEM\n",
    ")\n",
    "\n",
    "als_diversity_metrics = get_diversity_results(als_diversity_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af97c1fc-aabd-4a32-871d-223c34603d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog_coverage</th>\n",
       "      <th>distributional_coverage</th>\n",
       "      <th>novelty</th>\n",
       "      <th>diversity</th>\n",
       "      <th>serendipity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.515003</td>\n",
       "      <td>8.497723</td>\n",
       "      <td>11.391092</td>\n",
       "      <td>0.880526</td>\n",
       "      <td>0.868944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   catalog_coverage  distributional_coverage    novelty  diversity  \\\n",
       "1          0.515003                 8.497723  11.391092   0.880526   \n",
       "\n",
       "   serendipity  \n",
       "1     0.868944  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"catalog_coverage\", \"distributional_coverage\",\"novelty\", \"diversity\", \"serendipity\"]\n",
    "diversity_results = pd.DataFrame(columns=cols)\n",
    "\n",
    "diversity_results.loc[1] = als_diversity_metrics\n",
    "\n",
    "diversity_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c65d4-c957-4d2e-b257-cfbb6af9e8b0",
   "metadata": {},
   "source": [
    "## Combined results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c210d05-4e31-4af7-a489-af13f3f3718b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Algo</th>\n",
       "      <th>K</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Mean average precision</th>\n",
       "      <th>catalog_coverage</th>\n",
       "      <th>distributional_coverage</th>\n",
       "      <th>novelty</th>\n",
       "      <th>diversity</th>\n",
       "      <th>serendipity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100k</td>\n",
       "      <td>als</td>\n",
       "      <td>20</td>\n",
       "      <td>0.053287</td>\n",
       "      <td>0.038843</td>\n",
       "      <td>0.052833</td>\n",
       "      <td>0.007391</td>\n",
       "      <td>0.515003</td>\n",
       "      <td>8.497723</td>\n",
       "      <td>11.391092</td>\n",
       "      <td>0.880526</td>\n",
       "      <td>0.868944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Algo   K  Precision@k  Recall@k    NDCG@k  Mean average precision  \\\n",
       "1  100k  als  20     0.053287  0.038843  0.052833                0.007391   \n",
       "\n",
       "   catalog_coverage  distributional_coverage    novelty  diversity  \\\n",
       "1          0.515003                 8.497723  11.391092   0.880526   \n",
       "\n",
       "   serendipity  \n",
       "1     0.868944  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_results = generate_summary(MOVIELENS_DATA_SIZE, \"als\", TOP_K, als_ranking_metrics, als_diversity_metrics)\n",
    "cols = [\"Data\", \"Algo\", \"K\", \"Precision@k\", \"Recall@k\", \"NDCG@k\", \"Mean average precision\",\"catalog_coverage\", \"distributional_coverage\",\"novelty\", \"diversity\", \"serendipity\" ]\n",
    "summary_results = pd.DataFrame(columns = cols)\n",
    "summary_results.loc[1] = als_results\n",
    "summary_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4fe563-cfc1-40dd-becb-25885426f4bf",
   "metadata": {},
   "source": [
    "## Add rating evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b09051b0-99f5-40e0-9023-b1f2ad1946b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_rating_eval = SparkRatingEvaluation(\n",
    "    test_df, \n",
    "    top_all,  \n",
    "    col_user=\"UserId\", \n",
    "    col_item=\"MovieId\",\n",
    "    col_rating=\"Rating\", \n",
    "    col_prediction=\"prediction\")\n",
    "\n",
    "rating_results = get_rating_results(als_rating_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8af33237-40b0-4537-ba98-445de91c7659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>mean absolute error</th>\n",
       "      <th>R squared</th>\n",
       "      <th>explained variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.971761</td>\n",
       "      <td>0.757398</td>\n",
       "      <td>0.254696</td>\n",
       "      <td>0.259558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rmse  mean absolute error  R squared  explained variance\n",
       "1  0.971761             0.757398   0.254696            0.259558"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['rmse', 'mean absolute error', 'R squared','explained variance']\n",
    "\n",
    "rating_res = pd.DataFrame(columns=cols)\n",
    "rating_res.loc[1] = rating_results\n",
    "rating_res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49467e4-25ec-4c63-b5f8-c357fc8301a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Content based version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5d3c28-da42-4453-88ec-40c7e2c651f4",
   "metadata": {},
   "source": [
    "### convert text input into feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00132cdc-84db-4f8c-bede-52cdbacbe693",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------+\n",
      "|MovieId|               title|   genres|\n",
      "+-------+--------------------+---------+\n",
      "|    167|   Private Benjamin | [Comedy]|\n",
      "|   1343|         Lotto Land |  [Drama]|\n",
      "|   1607|  Hurricane Streets |  [Drama]|\n",
      "|    966|Affair to Remembe...|[Romance]|\n",
      "|      9|   Dead Man Walking |  [Drama]|\n",
      "+-------+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get movie features \"title\" and \"genres\"\n",
    "movies = (\n",
    "    data.groupBy(\"MovieId\", \"title\", \"genres\").count()\n",
    "    .na.drop()  # remove rows with null values\n",
    "    .withColumn(\"genres\", F.split(F.col(\"genres\"), \"\\|\"))  # convert to array of genres\n",
    "    .withColumn(\"title\", F.regexp_replace(F.col(\"title\"), \"[\\(),:^0-9]\", \"\"))  # remove year from title\n",
    "    .drop(\"count\")  # remove unused columns\n",
    ")\n",
    "movies.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55375b29-a603-4680-9dd3-29dcf9d86fdf",
   "metadata": {},
   "source": [
    "## tokenize title and remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c76bcd3-29a0-444d-a8e0-106f52077c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+\n",
      "|MovieId|               title|              genres|         title_words|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "|    167|   Private Benjamin |            [Comedy]| [private, benjamin]|\n",
      "|   1343|         Lotto Land |             [Drama]|       [lotto, land]|\n",
      "|   1607|  Hurricane Streets |             [Drama]|[hurricane, streets]|\n",
      "|    966|Affair to Remembe...|           [Romance]|[affair, to, reme...|\n",
      "|      9|   Dead Man Walking |             [Drama]|[dead, man, walking]|\n",
      "|   1230|Ready to Wear Pre...|            [Comedy]|[ready, to, wear,...|\n",
      "|   1118|        Up in Smoke |            [Comedy]|     [up, in, smoke]|\n",
      "|    673|          Cape Fear |[Film-Noir, Thril...|        [cape, fear]|\n",
      "|    879|     Peacemaker The |[Action, Thriller...|   [peacemaker, the]|\n",
      "|     66|While You Were Sl...|   [Comedy, Romance]|[while, you, were...|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenize \"title\" column\n",
    "title_tokenizer = Tokenizer(inputCol=\"title\", outputCol=\"title_words\")\n",
    "tokenized_data = title_tokenizer.transform(movies)\n",
    "tokenized_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0107fb13-8a10-46e3-967a-75a35650be05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|MovieId|              genres|                text|\n",
      "+-------+--------------------+--------------------+\n",
      "|    167|            [Comedy]| [private, benjamin]|\n",
      "|   1343|             [Drama]|       [lotto, land]|\n",
      "|   1607|             [Drama]|[hurricane, streets]|\n",
      "|    966|           [Romance]|  [affair, remember]|\n",
      "|      9|             [Drama]|[dead, man, walking]|\n",
      "|   1230|            [Comedy]|[ready, wear, pre...|\n",
      "|   1118|            [Comedy]|             [smoke]|\n",
      "|    673|[Film-Noir, Thril...|        [cape, fear]|\n",
      "|    879|[Action, Thriller...|        [peacemaker]|\n",
      "|     66|   [Comedy, Romance]|          [sleeping]|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"title_words\", outputCol=\"text\")\n",
    "clean_data = remover.transform(tokenized_data).drop(\"title\", \"title_words\")\n",
    "clean_data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05dd162-48e2-420f-aac7-02aaf6a50418",
   "metadata": {},
   "source": [
    "### convert text input into feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c67ec0b5-7a6c-42f9-b4fa-d92db7a8ab45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+--------------------+\n",
      "|MovieId|   genres|                text|       text_features|\n",
      "+-------+---------+--------------------+--------------------+\n",
      "|    167| [Comedy]| [private, benjamin]|(1024,[128,544],[...|\n",
      "|   1343|  [Drama]|       [lotto, land]|(1024,[38,300],[1...|\n",
      "|   1607|  [Drama]|[hurricane, streets]|(1024,[592,821],[...|\n",
      "|    966|[Romance]|  [affair, remember]|(1024,[389,502],[...|\n",
      "|      9|  [Drama]|[dead, man, walking]|(1024,[11,342,101...|\n",
      "+-------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# step 1: perform HashingTF on column \"text\"\n",
    "text_hasher = HashingTF(inputCol=\"text\", outputCol=\"text_features\", numFeatures=1024)\n",
    "hashed_data = text_hasher.transform(clean_data)\n",
    "hashed_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d444d932-711e-4f37-9e14-ba53bdbebded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+--------------------+---------------+\n",
      "|MovieId|   genres|                text|       text_features|genres_features|\n",
      "+-------+---------+--------------------+--------------------+---------------+\n",
      "|    167| [Comedy]| [private, benjamin]|(1024,[128,544],[...| (19,[1],[1.0])|\n",
      "|   1343|  [Drama]|       [lotto, land]|(1024,[38,300],[1...| (19,[0],[1.0])|\n",
      "|   1607|  [Drama]|[hurricane, streets]|(1024,[592,821],[...| (19,[0],[1.0])|\n",
      "|    966|[Romance]|  [affair, remember]|(1024,[389,502],[...| (19,[4],[1.0])|\n",
      "|      9|  [Drama]|[dead, man, walking]|(1024,[11,342,101...| (19,[0],[1.0])|\n",
      "+-------+---------+--------------------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# step 2: fit a CountVectorizerModel from column \"genres\".\n",
    "count_vectorizer = CountVectorizer(inputCol=\"genres\", outputCol=\"genres_features\")\n",
    "count_vectorizer_model = count_vectorizer.fit(hashed_data)\n",
    "vectorized_data = count_vectorizer_model.transform(hashed_data)\n",
    "vectorized_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b05277e-71ba-4cf7-89f8-f1689d04fed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------------------------------+\n",
      "|MovieId|features                                     |\n",
      "+-------+---------------------------------------------+\n",
      "|167    |(1043,[128,544,1025],[1.0,1.0,1.0])          |\n",
      "|1343   |(1043,[38,300,1024],[1.0,1.0,1.0])           |\n",
      "|1607   |(1043,[592,821,1024],[1.0,1.0,1.0])          |\n",
      "|966    |(1043,[389,502,1028],[1.0,1.0,1.0])          |\n",
      "|9      |(1043,[11,342,1014,1024],[1.0,1.0,1.0,1.0])  |\n",
      "|1230   |(1043,[597,740,902,1025],[1.0,1.0,1.0,1.0])  |\n",
      "|1118   |(1043,[702,1025],[1.0,1.0])                  |\n",
      "|673    |(1043,[169,690,1027,1040],[1.0,1.0,1.0,1.0]) |\n",
      "|879    |(1043,[909,1026,1027,1034],[1.0,1.0,1.0,1.0])|\n",
      "|66     |(1043,[256,1025,1028],[1.0,1.0,1.0])         |\n",
      "+-------+---------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# step 3: assemble features into a single vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"text_features\", \"genres_features\"],\n",
    "    outputCol=\"features\",\n",
    ")\n",
    "\n",
    "feature_data = assembler.transform(vectorized_data).select(\"MovieId\", \"features\")\n",
    "\n",
    "feature_data.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a18ab-00d1-484b-b7d9-91b3a217f7f1",
   "metadata": {},
   "source": [
    "The features column is represented with a SparseVector object. For example, in the feature vector (1043,[128,544,1025],[1.0,1.0,1.0]), 1043 is the vector length, indicating the vector consisting of 1043 item features. The values at index positions 128,544,1025 are 1.0, and the values at other positions are all 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b88e3-8b2d-4abc-968d-73e18fb2c097",
   "metadata": {},
   "source": [
    "### diversity metrics applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1903ba7a-9e29-4d64-b07b-46adcc6c4a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_eval = SparkDiversityEvaluation(\n",
    "    train_df = train_df, \n",
    "    reco_df = top_k_reco,\n",
    "    item_feature_df = feature_data, \n",
    "    item_sim_measure=\"item_feature_vector\",\n",
    "    col_user = COL_USER, \n",
    "    col_item = COL_ITEM\n",
    ")\n",
    "\n",
    "als_metrics = get_diversity_results(als_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2482a21-48aa-4d56-bd04-7833b40b36d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog_coverage</th>\n",
       "      <th>distributional_coverage</th>\n",
       "      <th>novelty</th>\n",
       "      <th>diversity</th>\n",
       "      <th>serendipity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.515003</td>\n",
       "      <td>8.497723</td>\n",
       "      <td>11.391092</td>\n",
       "      <td>0.871292</td>\n",
       "      <td>0.886252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   catalog_coverage  distributional_coverage    novelty  diversity  \\\n",
       "1          0.515003                 8.497723  11.391092   0.871292   \n",
       "\n",
       "   serendipity  \n",
       "1     0.886252  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"catalog_coverage\", \"distributional_coverage\",\"novelty\", \"diversity\", \"serendipity\"]\n",
    "content_diversity_results = pd.DataFrame(columns=cols)\n",
    "content_diversity_results.loc[1] = als_metrics\n",
    "content_diversity_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a62db0a0-6b7c-4d05-8b69-d77d15a1b82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog_coverage</th>\n",
       "      <th>distributional_coverage</th>\n",
       "      <th>novelty</th>\n",
       "      <th>diversity</th>\n",
       "      <th>serendipity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.515003</td>\n",
       "      <td>8.497723</td>\n",
       "      <td>11.391092</td>\n",
       "      <td>0.880526</td>\n",
       "      <td>0.868944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   catalog_coverage  distributional_coverage    novelty  diversity  \\\n",
       "1          0.515003                 8.497723  11.391092   0.880526   \n",
       "\n",
       "   serendipity  \n",
       "1     0.868944  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversity_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd604b2-cfab-41ed-8303-dbe3d64a7b13",
   "metadata": {},
   "source": [
    "## DISPLAY ALL RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d7e8303-0b39-436a-ae0e-5e561f87f9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS results for : 20 of the Movielens size: 100k \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ALS results for : {} of the Movielens size: {} \".format(TOP_K,MOVIELENS_DATA_SIZE))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5168e9ae-2904-4346-a4f3-68ed3eb088a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIVERSITY METRICS - COLLABORATIVE\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog_coverage</th>\n",
       "      <th>distributional_coverage</th>\n",
       "      <th>novelty</th>\n",
       "      <th>diversity</th>\n",
       "      <th>serendipity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.515003</td>\n",
       "      <td>8.497723</td>\n",
       "      <td>11.391092</td>\n",
       "      <td>0.880526</td>\n",
       "      <td>0.868944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   catalog_coverage  distributional_coverage    novelty  diversity  \\\n",
       "1          0.515003                 8.497723  11.391092   0.880526   \n",
       "\n",
       "   serendipity  \n",
       "1     0.868944  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"DIVERSITY METRICS - COLLABORATIVE\")\n",
    "print()\n",
    "diversity_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbbbef45-335b-4edb-ae7f-3a69ff6d6993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIVERSITY METRICS - CONTENT BASED\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog_coverage</th>\n",
       "      <th>distributional_coverage</th>\n",
       "      <th>novelty</th>\n",
       "      <th>diversity</th>\n",
       "      <th>serendipity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.515003</td>\n",
       "      <td>8.497723</td>\n",
       "      <td>11.391092</td>\n",
       "      <td>0.871292</td>\n",
       "      <td>0.886252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   catalog_coverage  distributional_coverage    novelty  diversity  \\\n",
       "1          0.515003                 8.497723  11.391092   0.871292   \n",
       "\n",
       "   serendipity  \n",
       "1     0.886252  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"DIVERSITY METRICS - CONTENT BASED\")\n",
    "print()\n",
    "content_diversity_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67aa2694-418e-4ab8-a55b-4047970e762c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RATING METRICS\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>mean absolute error</th>\n",
       "      <th>R squared</th>\n",
       "      <th>explained variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.971761</td>\n",
       "      <td>0.757398</td>\n",
       "      <td>0.254696</td>\n",
       "      <td>0.259558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rmse  mean absolute error  R squared  explained variance\n",
       "1  0.971761             0.757398   0.254696            0.259558"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"RATING METRICS\")\n",
    "print()\n",
    "rating_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4346269f-05b5-4a7b-9ec0-5fdfc897197c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANKING METRICS\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>NDCG@k</th>\n",
       "      <th>Mean average precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053287</td>\n",
       "      <td>0.038843</td>\n",
       "      <td>0.052833</td>\n",
       "      <td>0.007391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision@k  Recall@k    NDCG@k  Mean average precision\n",
       "1     0.053287  0.038843  0.052833                0.007391"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"RANKING METRICS\")\n",
    "print()\n",
    "ranking_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df255f5-a214-4c75-bbe7-945ccfa94237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condarec",
   "language": "python",
   "name": "condarec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
